1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?

Регуляризация устраняет переобучение за счёт внесения штрафа за сложность модели

L-1
к функции потерь (RMSE, MSE, ...) добавляем слагаемое, к-е отвечает за коэффициенты. мы добавляем слагаемое
равное произведению коэфф регуляризации умноженное на сумму модулей коэффициентов модели
Позволяет провести отбор признаков

L-2 
К функции потерь добавляется слагаемое, отвечающее за сложность модели и равное коэффициенту регуляризации
умноженное на сумму квадратов коэффициентов модели
Позволяет устранить мультиколлинеарность (сильное коррелирование) признаков

L1 + L2 = эластичная сеть



2. По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?

Feature importance оценивает, насколько важен каждый признак с точки зрения получения решений.
FI в случайном порядке считает разницу предсказанного значения каждого параметра со средним значением.
Результат варьирует в диапазоне от 0 до 1 для каждого признака, где 0 означает, что признак не используется,
1 - признак отлично предсказывает переменную. Важности всех признаков в сумме всегда дают 1.